# DAT

This repo is a combination [Distributed Adversarial Training to Robustify Deep Neural Networks at Scale](https://openreview.net/pdf?id=Srgg_ULj9gq) and [Communication-efficient Distributed Learning for Large Batch Optimization](https://proceedings.mlr.press/v162/liu22n.html).

[You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle](https://github.com/a1600012888/YOPO-You-Only-Propagate-Once)

[Pytorch-lamb](https://github.com/cybertronai/pytorch-lamb)

The repository is adjusted such that it can be run on Google Cloud with Multiple Node and Multiple GPUs, the details are in the [GCloud Interface Jupyter Notebook](https://github.com/Capsar/dat/blob/master/gcloud_interface.ipynb)
